\chapter{总结与展望}
\begin{fontsize}{15pt}{22.5pt}
    \begin{flushleft}
        \heiti 总结
    \end{flushleft}
\end{fontsize}

本文围绕协同边缘计算环境中分布式训练等复杂任务的资源调度问题展开研究，针对现有方法在任务建模与资源协同调度方面的不足，设计并实现了一套面向计算与网络资源联合调度的智能系统CES（Collaborative Edge Scheduler），主要贡献如下：

\begin{enumerate}[topsep = 0 pt, itemsep= 0 pt, parsep=0pt, partopsep=0pt, leftmargin=0pt, itemindent=44pt, labelsep=6pt, listparindent=24pt, label=(\arabic*)]
    \item 提出了计算与网络资源联合调度系统CES：该系统将任务到边缘节点的映射与网络带宽分配纳入统一调度框架，通过主从架构实现全局资源感知与协同决策，有效支持具有复杂通信拓扑的分布式智能任务。

   \item 构建了联合优化模型并设计了基于深度强化学习的调度算法CES-PPO：针对单作业调度场景，建立了同时考虑计算资源与网络资源的多目标优化模型，并提出基于近端策略优化（PPO）的双分支策略网络算法。该算法通过启发式奖励函数与动作掩码机制，引导智能体在动态环境中自主学习全局最优调度策略，显著提升了系统负载均衡度与带宽需求满足度。
   
   \item 扩展至多作业并发场景，提出CES-Multi-Jobs算法：在多作业队列调度问题中，设计了融合滚动窗口机制、资源感知综合评分与动态饥饿保护策略的启发式调度算法。该算法在保障作业公平性的同时，优化了带宽满足度、负载均衡度与平均等待时间，具有良好的可扩展性与实用性。
\end{enumerate}

通过仿真实验与真实环境部署验证，本文所提出的方法在多种任务规模、通信拓扑与负载条件下均表现出优于现有基线方法的综合性能，证明了联合调度机制在处理复杂边缘智能任务中的有效性与鲁棒性。

\begin{fontsize}{15pt}{22.5pt}
    \begin{flushleft}
        \heiti 展望
    \end{flushleft}
\end{fontsize}

尽管本文在协同边缘计算资源调度方面取得了一定进展，但仍存在若干值得深入研究的方向：
\begin{enumerate}[topsep = 0 pt, itemsep= 0 pt, parsep=0pt, partopsep=0pt, leftmargin=0pt, itemindent=44pt, labelsep=6pt, listparindent=24pt, label=(\arabic*)]
    \item 异构资源（如GPU/NPU）的扩展支持：随着边缘智能任务的多样化，GPU、NPU等异构计算资源日益重要。未来可将CES框架扩展至支持多种异构资源类型，并设计相应的资源建模与调度策略。

    \item 深度强化学习调度算法的改进：当前CES-PPO算法采用单智能体集中式决策范式，在处理大规模多作业并发场景时可能面临状态空间膨胀与决策效率瓶颈。未来可探索多智能体强化学习（MARL）方法，将每个作业或每个节点建模为独立智能体，通过协作与竞争机制实现分布式联合调度，提升系统的可扩展性与鲁棒性。同时，可引入大语言模型（LLM）作为先验知识注入或决策辅助模块，利用其强大的常识推理与模式识别能力，增强算法对复杂动态环境的适应性与可解释性。
    
    \item 动态环境下的自适应参数调优：当前CES-Multi-Jobs算法中的部分超参数（如窗口扩展因子、等待敏感因子等）依赖于经验设定。未来可引入元学习或在线优化方法，实现参数的自适应调整，以进一步提升算法在高度动态环境中的适应能力。
\end{enumerate}

综上所述，本文为协同边缘计算环境下的资源联合调度提供了系统的解决方案，未来可在智能化、异构化与安全化方向进一步拓展，助力边缘智能应用的广泛落地。